{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des librairies et démarrage de la session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données et formatage des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des deux datasets en csv et suppression des colonnes \"month\" et \"year\" de trips car doublon d'une autre colonne\n",
    "df_trips = spark.read.csv(\"data/Austin bikes/austin_bikeshare_trips.csv\", header=True, inferSchema=True).drop(\"month\",\"year\")\n",
    "df_stations = spark.read.csv(\"data/Austin bikes/austin_bikeshare_stations.csv\", header=True, inferSchema=True)\n",
    "\n",
    "#Changement de types de données (pour la plupart, passer de double à integer)\n",
    "df_trips = df_trips.withColumn(\"bikeid\", df_trips[\"bikeid\"].cast(\"integer\"))\\\n",
    "    .withColumn(\"trip_id\", df_trips[\"trip_id\"].cast(\"integer\"))\\\n",
    "    .withColumn(\"start_station_id\", df_trips[\"start_station_id\"].cast(\"integer\"))\\\n",
    "    .withColumn(\"end_station_id\", df_trips[\"end_station_id\"].cast(\"integer\"))\\\n",
    "    .withColumn(\"start_datetime\", F.to_timestamp(df_trips[\"start_time\"])).drop(\"start_time\")\n",
    "\n",
    "#Création d'une colonne \"date\" en plus de la colonne \"datetime\" pour avoir les deux\n",
    "df_trips = df_trips.withColumn(\"date\", F.to_date(df_trips[\"start_datetime\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----------------+--------------+--------------------+----------------+--------------------+--------------------+----------+-------------------+----------+\n",
      "|bikeid|checkout_time|duration_minutes|end_station_id|    end_station_name|start_station_id|  start_station_name|     subscriber_type|   trip_id|     start_datetime|      date|\n",
      "+------+-------------+----------------+--------------+--------------------+----------------+--------------------+--------------------+----------+-------------------+----------+\n",
      "|     8|     19:12:00|              41|          2565|Trinity & 6th Street|            2536|    Waller & 6th St.|             Walk Up|1310148290|2015-03-19 19:12:00|2015-03-19|\n",
      "|   141|      2:06:04|               6|          2570|South Congress & ...|            2494|      2nd & Congress|            Local365|  12617682|2016-10-30 02:06:04|2016-10-30|\n",
      "|   578|     16:28:27|              13|          2498|Convention Center...|            2538|Bullock Museum @ ...|            Local365|   9075366|2016-03-11 16:28:27|2016-03-11|\n",
      "|   555|     15:12:00|              80|          2712|Toomey Rd @ South...|            2497|Capitol Station /...|24-Hour Kiosk (Au...|1310384706|2014-11-23 15:12:00|2014-11-23|\n",
      "|    86|     15:39:13|              25|          3377|MoPac Pedestrian ...|            2707|Rainey St @ Cummings|             Walk Up|  14468597|2017-04-16 15:39:13|2017-04-16|\n",
      "+------+-------------+----------------+--------------+--------------------+----------------+--------------------+--------------------+----------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bikeid: integer (nullable = true)\n",
      " |-- checkout_time: string (nullable = true)\n",
      " |-- duration_minutes: integer (nullable = true)\n",
      " |-- end_station_id: integer (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- start_station_id: integer (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- subscriber_type: string (nullable = true)\n",
      " |-- trip_id: integer (nullable = true)\n",
      " |-- start_datetime: timestamp (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trips.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitements (Group by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+---------------+---------------------+\n",
      "|      date|checkout_time|subscriber_type|avg(duration_minutes)|\n",
      "+----------+-------------+---------------+---------------------+\n",
      "|2015-03-17|     11:12:00|        Walk Up|    42.24242424242424|\n",
      "|2015-01-30|     17:12:00|        Local30|                 13.5|\n",
      "|2015-10-02|     15:12:19|       Local365|                 17.0|\n",
      "|2016-08-19|     18:47:49|        Walk Up|                 14.0|\n",
      "|2017-01-01|     16:29:22|        Walk Up|                 28.0|\n",
      "+----------+-------------+---------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Groupement en faisant la moyenne de la durée des trajets par jour\n",
    "df_avg_duration_per_day = df_trips.groupBy(\"date\",\"checkout_time\",\"subscriber_type\").mean(\"duration_minutes\")\n",
    "df_avg_duration_per_day.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------+--------------------+-----+\n",
      "|      date|  start_station_name|checkout_time|     subscriber_type|count|\n",
      "+----------+--------------------+-------------+--------------------+-----+\n",
      "|2015-12-31|Riverside @ S. Lamar|     15:12:58|             Walk Up|    1|\n",
      "|2015-10-02|Toomey Rd @ South...|     15:12:19|            Local365|    1|\n",
      "|2017-07-24|      4th & Congress|     14:05:21|           Weekender|    1|\n",
      "|2016-05-20|Riverside @ S. Lamar|     20:32:12|             Walk Up|    1|\n",
      "|2014-03-15|      2nd & Congress|     23:12:00|24-Hour Kiosk (Au...|   13|\n",
      "+----------+--------------------+-------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Groupement en comptant le nombre de trajets par jour\n",
    "df_trips_per_start_station = df_trips.groupBy(\"date\",\"start_station_name\",\"checkout_time\",\"subscriber_type\").count()\n",
    "df_trips_per_start_station.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------+--------------------+-----+\n",
      "|      date|    end_station_name|checkout_time|     subscriber_type|count|\n",
      "+----------+--------------------+-------------+--------------------+-----+\n",
      "|2015-11-13|      2nd & Congress|     17:12:31|             Walk Up|    1|\n",
      "|2015-04-02|Barton Springs @ ...|     20:12:00|             Walk Up|    5|\n",
      "|2015-05-17|UT West Mall @ Gu...|      2:12:00|             Walk Up|    4|\n",
      "|2014-05-17|      4th & Congress|     16:12:00|24-Hour Kiosk (Au...|    1|\n",
      "|2015-03-15|East 6th at Rober...|     17:12:00|            Local365|    1|\n",
      "+----------+--------------------+-------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Groupement en comptant le nombre de trajets par jour\n",
    "df_trips_per_end_station = df_trips.groupBy(\"date\",\"end_station_name\",\"checkout_time\",\"subscriber_type\").count()\n",
    "df_trips_per_end_station.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#On exporte les datasets modifiés et créés en csv\n",
    "df_trips.repartition(1).write.format('csv').mode('overwrite').option(\"header\", \"true\").save('data/Output/df_trip.csv')\n",
    "\n",
    "df_avg_duration_per_day.repartition(1).write.format('csv').mode('overwrite').option(\"header\", \"true\").save('data/Output/df_avg_duration_day.csv')\n",
    "\n",
    "df_trips_per_start_station.repartition(1).write.format('csv').mode('overwrite').option(\"header\", \"true\").save('data/Output/df_trips_start_station.csv')\n",
    "\n",
    "df_trips_per_end_station.repartition(1).write.format('csv').mode('overwrite').option(\"header\", \"true\").save('data/Output/df_trips_end_station.csv')\n",
    "\n",
    "df_stations.repartition(1).write.format('csv').mode('overwrite').option(\"header\", \"true\").save('data/Output/df_station.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby table Date Unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      date|\n",
      "+----------+\n",
      "|2015-03-19|\n",
      "|2016-10-30|\n",
      "|2016-03-11|\n",
      "|2014-11-23|\n",
      "|2017-04-16|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+\n",
      "|      date|\n",
      "+----------+\n",
      "|2014-09-26|\n",
      "|2016-03-01|\n",
      "|2015-05-19|\n",
      "|2014-11-12|\n",
      "|2015-03-09|\n",
      "|2017-01-06|\n",
      "|2015-03-06|\n",
      "|2016-07-26|\n",
      "|2015-04-09|\n",
      "|2016-10-03|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Table unique de date\n",
    "df_Date = df_trips.select(\"date\")\n",
    "df_Date.show(5)\n",
    "df_Date.dropDuplicates().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|checkout_time|\n",
      "+-------------+\n",
      "|     19:12:00|\n",
      "|      2:06:04|\n",
      "|     16:28:27|\n",
      "|     15:12:00|\n",
      "|     15:39:13|\n",
      "+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------+\n",
      "|checkout_time|\n",
      "+-------------+\n",
      "|     18:54:06|\n",
      "|     12:45:09|\n",
      "|     19:15:02|\n",
      "|     10:12:05|\n",
      "|     14:06:41|\n",
      "|     16:10:56|\n",
      "|     19:43:39|\n",
      "|     15:08:58|\n",
      "|     18:09:52|\n",
      "|     15:00:39|\n",
      "+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Table unique de date\n",
    "df_heure = df_trips.select(\"checkout_time\")\n",
    "df_heure.show(5)\n",
    "df_heure.dropDuplicates().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     subscriber_type|\n",
      "+--------------------+\n",
      "|             Walk Up|\n",
      "|            Local365|\n",
      "|            Local365|\n",
      "|24-Hour Kiosk (Au...|\n",
      "|             Walk Up|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+\n",
      "|     subscriber_type|\n",
      "+--------------------+\n",
      "|              Annual|\n",
      "|24-Hour Membershi...|\n",
      "| Semester Membership|\n",
      "|Annual (Madison B...|\n",
      "|Annual (Cincy Red...|\n",
      "|Annual (Nashville...|\n",
      "|Annual Membership...|\n",
      "|24-Hour-Online (A...|\n",
      "|     Founding Member|\n",
      "|Membership: pay o...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Table unique de subscriber\n",
    "df_sub = df_trips.select(\"subscriber_type\")\n",
    "df_sub.show(5)\n",
    "df_sub.dropDuplicates().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## exporter les data\n",
    "df_Date.repartition(1).write.format('csv').mode('overwrite').option(\"header\", \"true\").save('data/Output/df_Date.csv')\n",
    "df_heure.repartition(1).write.format('csv').mode('overwrite').option(\"header\", \"true\").save('data/Output/df_heure.csv')\n",
    "df_sub.repartition(1).write.format('csv').mode('overwrite').option(\"header\", \"true\").save('data/Output/df_sub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------+--------+-------------+------------+------------+-------------------+------------------+------------------+--------------------------+-------------------------+-------------------------+-------------------+------------------+------------------+-----------+----------+-----------+----------------------+-------------------+\n",
      "|      Date|TempHighF|TempAvgF|TempLowF|DewPointHighF|DewPointAvgF|DewPointLowF|HumidityHighPercent|HumidityAvgPercent|HumidityLowPercent|SeaLevelPressureHighInches|SeaLevelPressureAvgInches|SeaLevelPressureLowInches|VisibilityHighMiles|VisibilityAvgMiles|VisibilityLowMiles|WindHighMPH|WindAvgMPH|WindGustMPH|PrecipitationSumInches|             Events|\n",
      "+----------+---------+--------+--------+-------------+------------+------------+-------------------+------------------+------------------+--------------------------+-------------------------+-------------------------+-------------------+------------------+------------------+-----------+----------+-----------+----------------------+-------------------+\n",
      "|2013-12-21|       74|      60|      45|           67|          49|          43|                 93|                75|                57|                     29.86|                    29.68|                    29.59|                 10|                 7|                 2|         20|         4|         31|                  0.46|Rain , Thunderstorm|\n",
      "|2013-12-22|       56|      48|      39|           43|          36|          28|                 93|                68|                43|                     30.41|                    30.13|                    29.87|                 10|                10|                 5|         16|         6|         25|                     0|                   |\n",
      "|2013-12-23|       58|      45|      32|           31|          27|          23|                 76|                52|                27|                     30.56|                    30.49|                    30.41|                 10|                10|                10|          8|         3|         12|                     0|                   |\n",
      "|2013-12-24|       61|      46|      31|           36|          28|          21|                 89|                56|                22|                     30.56|                    30.45|                     30.3|                 10|                10|                 7|         12|         4|         20|                     0|                   |\n",
      "|2013-12-25|       58|      50|      41|           44|          40|          36|                 86|                71|                56|                     30.41|                    30.33|                    30.27|                 10|                10|                 7|         10|         2|         16|                     T|                   |\n",
      "+----------+---------+--------+--------+-------------+------------+------------+-------------------+------------------+------------------+--------------------------+-------------------------+-------------------------+-------------------+------------------+------------------+-----------+----------+-----------+----------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weather = spark.read.csv(\"data/Austin weather/austin_weather.csv\", header=True, inferSchema=True)\n",
    "df_weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------------------+-------------------+\n",
      "|      Date|TempAvgF|PrecipitationSumInches|             Events|\n",
      "+----------+--------+----------------------+-------------------+\n",
      "|2013-12-21|      60|                  0.46|Rain , Thunderstorm|\n",
      "|2013-12-22|      48|                     0|                   |\n",
      "|2013-12-23|      45|                     0|                   |\n",
      "|2013-12-24|      46|                     0|                   |\n",
      "|2013-12-25|      50|                     T|                   |\n",
      "+----------+--------+----------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weather = spark.read.csv(\"data/Austin weather/austin_weather.csv\", header=True, inferSchema=True)\\\n",
    ".select(\"Date\", \"TempAvgF\", \"PrecipitationSumInches\", \"Events\")\n",
    "df_weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion des pouces et fahrenheint en cm et celsius\n",
    "df_weather = df_weather.withColumn(\"Temp_Avg_Celsius\", (F.col(\"TempAvgF\")-32)*(5/9))\\\n",
    "    .withColumn(\"Precipitations_cm\", F.col(\"PrecipitationSumInches\")*2.54 )\n",
    "df_weather = df_weather.drop(\"PrecipitationSumInches\",\"TempAvgF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+----------+-----+\n",
      "|             Events|   Temp_Avg_Celsius|  Precipitations_cm|      date|count|\n",
      "+-------------------+-------------------+-------------------+----------+-----+\n",
      "|                   | 24.444444444444446|                0.0|2014-09-26|  503|\n",
      "|                   |  21.11111111111111|                0.0|2016-03-01|  411|\n",
      "|               Rain|  27.77777777777778|               null|2015-05-19|  438|\n",
      "|                   |  6.666666666666667|                0.0|2014-11-12|  164|\n",
      "|               Rain|  11.11111111111111|             5.5118|2015-03-09|   66|\n",
      "|                   |-1.6666666666666667|                0.0|2017-01-06|  107|\n",
      "|                   |  5.555555555555555|                0.0|2015-03-06|  354|\n",
      "|Rain , Thunderstorm|  28.88888888888889|0.20320000000000002|2016-07-26|  439|\n",
      "|                   |  26.11111111111111|                0.0|2015-04-09|  503|\n",
      "|                   |  23.88888888888889|                0.0|2016-10-03|  684|\n",
      "+-------------------+-------------------+-------------------+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set('spark.sql.caseSensitive', True)\n",
    "df_trips_per_day = df_trips.groupBy(\"date\").count()\n",
    "df_join = df_weather.join(df_trips_per_day,df_weather.Date == df_trips_per_day.date,\"inner\")\n",
    "df_join = df_join.drop(\"Date\")\n",
    "df_join.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.repartition(1).write.format('csv').mode('overwrite').option(\"header\", \"true\").save('data/Output/df_weather.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
